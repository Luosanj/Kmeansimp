getwd()
devtools::document()
devtools::document()
devtools::document()
devtools::build()
devtools::document()
warnings()
Rcpp::compileAttributes()
devtools::document()
library(usethis)
usethis::use_vignette()
usethis::use_vignette(Tutorial)
usethis::use_vignette('Tutorial')
library(Kmeansimp)
Kmeansimp(df, 2, iter = 20)
df = matrix(c(1:1000), 500, 2)
Kmeansimp(df, 2, iter = 20)
library(Kmeansimp)
library(Kmeansimp)
df = matrix(c(1:1000), 500, 2)
Kmeansimp(df, 2, iter = 20)
Kmeansimp(df, 2, 10)
Kmeansimp(df, 2, 3)
df = matrix(c(1:100), 50, 2)
Kmeansimp(df, 2, iter = 20)
df = matrix(c(1:1000), 500, 2)
Kmeansimp(df, 2, iter = 3)
system.time(Kmeansimp(matrix(c(1:900000), 300000, 3), 2))
X = matrix(runif(900000, 0, 10), 300000, 3)
# kmeans
library(Rcpp)
kmeans_imp = function(data, n, iter = 10){
# algorithm = 'Lloyd'
if(!is.matrix(data) && !is.data.frame(data)){
stop('Input dataset must be a dataframe or matrix !')
}
if(!(n == round(n)) || n < 1L){
stop('Number of clusters must be a positive integer!')
}
size <<- nrow(data)
if(n >= size){
stop('Number of clusters must be above 0 and below sample size !')
}
if(n == 1L){
warning('1 cluster is the dataset itself!')
}
dataset <<- as.matrix(data)
maxiter <<- iter
k <<- n
oriCluster <<- c()
curCluster <<- c()
geCentroids()
doCluster()
proCluster()
sizeVec = statSize() # count number of each cluster
between_SS = witSS()
result = list()
result[[1]] = sizeVec
result[[2]] = centroids
result[[3]] = curCluster
result[[4]] = between_SS
result[[5]] = round(1 - prop, 2L)
names(result) = c('each_cluster_size',
'Cluster_means',
'Clustering_Vevtor:',
'Within_cluster_sum_of_squares(withinSS)',
'proportion of betweenSS with totalSS')
return(result)
}
# ********Innovation : generate centroids********
geCentroids = function(){
centroids <<- matrix(nrow = k, ncol = ncol(dataset))
centroids[1,] <<- dataset[sample(nrow(dataset), 1),]
exdata = dataset
sizex = nrow(exdata)
i = 2
while(i <= k){
exdist = c()
if(i == 2){
for(l in c(1 : sizex)){
exdist[l] = sum((centroids[1, ] - exdata[l, ])^2L)
}
}else{
for(l in c(1 : sizex)){
exdist[l] = sum(sweep(centroids[1:(i-1), ], 2, exdata[l, ])^2L)
}
}
dindex = which.max(exdist)
centroids[i, ] <<- exdata[dindex, ]
exdata = exdata[-dindex,, drop = FALSE]
sizex = sizex - 1
i = i + 1
}
print('start')
print(centroids)
}
# split cluster first
doCluster = function(){
for(i in c(1L : size)){
dist = c() # a vector to contain distances to centroids.
for(j in c(1L : k)){
dist[j] = sum((dataset[i, ] - centroids[j, ])^2L)
}
curCluster[i] <<- which.min(dist)
}
}
# update centroids
upCentroids = function(){
for(j in c(1L : k)){
clu_index = which(oriCluster == j)
points = dataset[clu_index, ]
centroids[j, ] <<- colMeans(points)
}
}
# recluster until converge or maximum iterations
proCluster = function(){
flag = FALSE
numiter = 2L
while(numiter <= maxiter | flag == TRUE){
oriCluster <<- curCluster
upCentroids()
print(centroids)
doCluster()
if(identical(oriCluster, curCluster)){
flag = TRUE
}
numiter = numiter + 1L
}
if(!flag){
warning('Clustering did not converge, more iterations are suggested!')
}
}
# count numbers of each cluster
statSize = function(){
sizeVec = c()
for(j in c(1L : k)){
sizeVec[j] = sum(curCluster == j)
}
return(sizeVec)
}
# clusters within sum of squares and proportion of total sum of squares
witSS = function(){
distSS = c(rep(0L, k))
for(j in c(1L : k)){
index = which(curCluster == j)
distSS[j] = sum(sweep(dataset[index, ], 2, centroids[j, ])^2L)
}
centroidAll = colMeans(dataset)
totalSS <<- sum(sweep(X, 2, colMeans(X))^2L)
prop <<- sum(distSS) / totalSS
return(distSS)
}
system.time(Kmeans_imp(matrix(c(1:900000), 300000, 3), 2))
system.time(kmeans_imp(matrix(c(1:900000), 300000, 3), 2))
Kmeansimp(df, 2, iter = 20)$Cluster_means
library(Kmeansimp)
Kmeansimp(df, 2, iter = 20)$Cluster_means
